# ğŸ§  How To â€” Data Science no Projeto ChurnInsight

Este documento explica **como o time de Data Science deve trabalhar dentro do projeto ChurnInsight**, garantindo organizaÃ§Ã£o, liberdade de experimentaÃ§Ã£o e integraÃ§Ã£o com o restante da arquitetura.

O foco aqui Ã© **orientar**, nÃ£o engessar.

---

## ğŸ¯ Objetivo do Time de Data Science

O time de Data Science Ã© responsÃ¡vel por:

- Explorar o dataset de churn
- Entender padrÃµes de comportamento dos clientes
- Criar e testar features relevantes
- Treinar modelos de classificaÃ§Ã£o
- Avaliar mÃ©tricas
- Contribuir para a escolha do modelo final


---

## ğŸ“ Estrutura de Pastas para Data Science

### Dataset compartilhado

Somente o dataset original Ã© compartilhado entre todos:

```
data/raw/
```

âš ï¸ NÃ£o modifique arquivos dentro de `raw/`.

---

### Notebooks individuais

Cada cientista de dados possui seu prÃ³prio espaÃ§o:

```
notebooks/individual/<seu_nome>/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ features/
â”œâ”€â”€ 01_eda.ipynb
â”œâ”€â”€ 02_features.ipynb
â”œâ”€â”€ 03_modelagem.ipynb
â””â”€â”€ README.md
```

Isso garante:
- liberdade total de experimentaÃ§Ã£o
- nenhum conflito entre notebooks
- autonomia tÃ©cnica

---

## ğŸ” ReutilizaÃ§Ã£o de CÃ³digo (Recomendado)

O projeto possui um **core de funÃ§Ãµes reutilizÃ¡veis** em:

```
src/
```

Exemplos:
- carregamento de dados
- preprocessamento padrÃ£o
- avaliaÃ§Ã£o de mÃ©tricas

VocÃª pode:
- importar essas funÃ§Ãµes nos seus notebooks
- adaptÃ¡-las localmente se preferir

Nada Ã© obrigatÃ³rio.

---

## ğŸ“Š Fluxo de Trabalho Sugerido

1. Copie o dataset de `data/raw/`
2. FaÃ§a EDA livre no seu notebook
3. Crie e teste features
4. Treine um ou mais modelos
5. Avalie mÃ©tricas
6. Documente decisÃµes no README do seu diretÃ³rio

---

## ğŸ“Œ Boas PrÃ¡ticas

- Documente suas hipÃ³teses
- Salve grÃ¡ficos importantes
- Explique decisÃµes (mesmo que simples)
- Prefira clareza a complexidade
- NÃ£o se preocupe em "acertar" o modelo perfeito


---

## ğŸ¤ IntegraÃ§Ã£o com o Modelo Final

Ao longo do projeto, os notebooks individuais servirÃ£o como espaÃ§o de exploraÃ§Ã£o, aprendizado e geraÃ§Ã£o de insights sobre os dados.
Os principais aprendizados, padrÃµes observados e ideias de features poderÃ£o ser considerados na consolidaÃ§Ã£o do modelo final, que serÃ¡ treinado de forma centralizada para garantir:
- consistÃªncia do pipeline,
- reprodutibilidade dos resultados,
- compatibilidade com a API de inferÃªncia.
O modelo final serÃ¡ exportado e utilizado pela API como artefato oficial do projeto, mantendo os notebooks individuais livres para experimentaÃ§Ã£o sem impacto direto na integraÃ§Ã£o.